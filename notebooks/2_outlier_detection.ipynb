{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constract data model to separate outliers form normal data and noise.\n",
    "\n",
    "types of methods:\n",
    "* Density based\n",
    "* Distance base\n",
    "* Parametric\n",
    "\n",
    "Speaking falls into three categories: density-based methods, distance-based methods, and parametric methods.\n",
    "Density-based and distance-based methods fall into the category of spatial proximity algorithms. Examples include DBSCAN, k-means, and k-nearest neighbor.\n",
    "Parametric methods usually assume some sort of form to the data, such as normality. Examples include Gaussian mixture model, single class Williams, and Z-score.\n",
    "Other methods that are not specifically machine learning methods, such as Z-score, also assume normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from src.preprocessor import preprocessor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score, train_test_split, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Read data\n",
    "data_dir = Path(\"/home/reinis/Documents/House Prices - Advanced Regression Techniques/data\")\n",
    "train_df = pd.read_csv(data_dir / \"train.csv\")\n",
    "test_df = pd.read_csv(data_dir / \"test.csv\")\n",
    "\n",
    "# Separate target form predictors\n",
    "dfx = train_df.copy()\n",
    "label = dfx.pop(\"SalePrice\")\n",
    "\n",
    "X = pd.DataFrame(preprocessor.fit_transform(dfx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05\n",
    "\n",
    "anomaly_algorithms = [\n",
    "    (\"Robust covariance\", EllipticEnvelope(contamination=outliers_fraction)),\n",
    "    (\"Isolation Forest\", IsolationForest(contamination=outliers_fraction, random_state=42)),\n",
    "    (\"Local Outlier Factor\", LocalOutlierFactor(n_neighbors=35, contamination=outliers_fraction,novelty=True)),\n",
    "]\n",
    "\n",
    "lr_pipeline = make_pipeline(\n",
    "    SelectFromModel(LassoCV()),\n",
    "    TransformedTargetRegressor(\n",
    "        regressor=RidgeCV(), \n",
    "        func=np.log10, \n",
    "        inverse_func=sp.special.exp10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4195/4009405075.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"Algorithm\": \"Simple Linear Regression\", \"MSE\": mse}, ignore_index=True)\n",
      "/home/reinis/.local/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:745: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_4195/4009405075.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"Algorithm\": name, \"MSE\": mse, \"Inliers Shape\": X[inliers].shape, \"Inliers\":X[inliers], \"Outliers\": X[~inliers].index}, ignore_index=True)\n",
      "/tmp/ipykernel_4195/4009405075.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"Algorithm\": name, \"MSE\": mse, \"Inliers Shape\": X[inliers].shape, \"Inliers\":X[inliers], \"Outliers\": X[~inliers].index}, ignore_index=True)\n",
      "/tmp/ipykernel_4195/4009405075.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\"Algorithm\": name, \"MSE\": mse, \"Inliers Shape\": X[inliers].shape, \"Inliers\":X[inliers], \"Outliers\": X[~inliers].index}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Algorithm\", \"MSE\"])\n",
    "\n",
    "# Fit the linear regression pipeline to the entire dataset\n",
    "lr_pipeline.fit(X, label)\n",
    "\n",
    "# Predict the target variable for the entire dataset\n",
    "y_pred = lr_pipeline.predict(X)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(label, y_pred)\n",
    "\n",
    "# Append the results to the dataframe\n",
    "results_df = results_df.append({\"Algorithm\": \"Simple Linear Regression\", \"MSE\": mse}, ignore_index=True)\n",
    "\n",
    "\n",
    "for name, algorithm in anomaly_algorithms:\n",
    "# Fit the algorithm to the data\n",
    "    algorithm.fit(X)\n",
    "    # Predict the anomaly scores for each sample\n",
    "    anomaly_scores = algorithm.decision_function(X)\n",
    "\n",
    "    # Extract the samples that are considered inliers (not anomalies)\n",
    "    inliers = anomaly_scores > 0\n",
    "\n",
    "    # Fit the linear regression pipeline to the inlier samples\n",
    "    lr_pipeline.fit(X[inliers], label[inliers])\n",
    "\n",
    "    # Predict the target variable for the inlier samples\n",
    "    y_pred = lr_pipeline.predict(X[inliers])\n",
    "\n",
    "    # Calculate the mean squared error\n",
    "    mse = mean_squared_error(label[inliers], y_pred)\n",
    "\n",
    "    # Append the results to the dataframe\n",
    "    results_df = results_df.append({\"Algorithm\": name, \"MSE\": mse, \"Inliers Shape\": X[inliers].shape, \"Inliers\":X[inliers], \"Outliers\": X[~inliers].index}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Inliers Shape</th>\n",
       "      <th>Inliers</th>\n",
       "      <th>Outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>4.860369e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robust covariance</td>\n",
       "      <td>3.201183e+08</td>\n",
       "      <td>(1387, 236)</td>\n",
       "      <td>0         1         2         3    ...</td>\n",
       "      <td>Int64Index([  17,   39,   51,   52,   88,  102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>2.787941e+08</td>\n",
       "      <td>(1387, 236)</td>\n",
       "      <td>0         1         2         3    ...</td>\n",
       "      <td>Int64Index([  39,   48,   87,   88,  125,  178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Local Outlier Factor</td>\n",
       "      <td>2.884932e+08</td>\n",
       "      <td>(1392, 236)</td>\n",
       "      <td>0         1         2         3    ...</td>\n",
       "      <td>Int64Index([  70,  113,  159,  170,  178,  185...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Algorithm           MSE Inliers Shape  \\\n",
       "0  Simple Linear Regression  4.860369e+08           NaN   \n",
       "1         Robust covariance  3.201183e+08   (1387, 236)   \n",
       "2          Isolation Forest  2.787941e+08   (1387, 236)   \n",
       "3      Local Outlier Factor  2.884932e+08   (1392, 236)   \n",
       "\n",
       "                                             Inliers  \\\n",
       "0                                                NaN   \n",
       "1             0         1         2         3    ...   \n",
       "2             0         1         2         3    ...   \n",
       "3             0         1         2         3    ...   \n",
       "\n",
       "                                            Outliers  \n",
       "0                                                NaN  \n",
       "1  Int64Index([  17,   39,   51,   52,   88,  102...  \n",
       "2  Int64Index([  39,   48,   87,   88,  125,  178...  \n",
       "3  Int64Index([  70,  113,  159,  170,  178,  185...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  39,   48,   87,   88,  125,  178,  185,  197,  198,  250,  291,\n",
       "             307,  335,  349,  375,  386,  431,  434,  440,  496,  515,  520,\n",
       "             523,  533,  581,  614,  635,  636,  649,  664,  691,  705,  738,\n",
       "             747,  769,  778,  798,  803,  825,  828,  843,  897,  898,  914,\n",
       "             921,  942,  954,  977, 1011, 1030, 1061, 1142, 1169, 1173, 1181,\n",
       "            1182, 1219, 1228, 1230, 1234, 1243, 1268, 1283, 1298, 1323, 1326,\n",
       "            1337, 1349, 1373, 1386, 1387, 1423, 1449],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"Outliers\"][2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightly-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "191a0500f25484430c7aad1a9323aeb602c32d6171746e97eb0830e5c8b0f62c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
